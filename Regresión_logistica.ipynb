{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import randint\n",
    "import multiprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "\n",
    "# Bayesian\n",
    "# ==============================================================================\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "import time\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CTE</th>\n",
       "      <th>DEBITO_DIR</th>\n",
       "      <th>ID_EMPLEADO</th>\n",
       "      <th>ID_SEGMENTO_VALOR</th>\n",
       "      <th>ANTIGUEDAD</th>\n",
       "      <th>RENTA</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>EDAD_PUNTAJE</th>\n",
       "      <th>ID_GENERO</th>\n",
       "      <th>ACEPTADO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87218.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>122179.11</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>119775.54</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22220.04</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>295590.36</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>97397.16</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>168445.62</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>53689.02</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>64404.21</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>97879.50</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602560 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CT_CTE  DEBITO_DIR  ID_EMPLEADO  ID_SEGMENTO_VALOR  ANTIGUEDAD  \\\n",
       "0          1.0         0.0          0.0                2.0         6.0   \n",
       "1          1.0         0.0          0.0                1.0        35.0   \n",
       "2          0.0         0.0          0.0                1.0        35.0   \n",
       "3          1.0         0.0          0.0                1.0        35.0   \n",
       "4          1.0         0.0          0.0                1.0        35.0   \n",
       "...        ...         ...          ...                ...         ...   \n",
       "602555     0.0         0.0          0.0                2.0        62.0   \n",
       "602556     0.0         0.0          0.0                2.0         7.0   \n",
       "602557     0.0         0.0          0.0                1.0         6.0   \n",
       "602558     0.0         0.0          0.0                2.0       229.0   \n",
       "602559     0.0         0.0          0.0                2.0        52.0   \n",
       "\n",
       "            RENTA  EDAD  EDAD_PUNTAJE  ID_GENERO  ACEPTADO  \n",
       "0        87218.10  36.0           3.0        1.0       0.0  \n",
       "1       122179.11  23.0           1.0        0.0       0.0  \n",
       "2       119775.54  23.0           1.0        1.0       0.0  \n",
       "3        22220.04  24.0           1.0        1.0       0.0  \n",
       "4       295590.36  24.0           1.0        1.0       0.0  \n",
       "...           ...   ...           ...        ...       ...  \n",
       "602555   97397.16  41.0           6.0        1.0       0.0  \n",
       "602556  168445.62  34.0           2.0        0.0       0.0  \n",
       "602557   53689.02  24.0           1.0        1.0       0.0  \n",
       "602558   64404.21  61.0           7.0        0.0       0.0  \n",
       "602559   97879.50  54.0           7.0        0.0       0.0  \n",
       "\n",
       "[602560 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_final = pd.read_csv('Tabla_final_colab.csv', sep = \",\")\n",
    "\n",
    "\n",
    "## Se borran columnas irrelevantes ##\n",
    "tabla_final = tabla_final.drop('FECHA_DATO', axis=1)\n",
    "tabla_final = tabla_final.drop('FECHA_PROCESO', axis=1)\n",
    "tabla_final = tabla_final.drop('ID_PROD', axis=1)\n",
    "tabla_final = tabla_final.drop('FLAG_PREAP', axis=1)\n",
    "\n",
    "## Definimos una tabla con los id de clientes\n",
    "## Para luego poeder funtarla con las prob ##\n",
    "## Si se queda se considera como parametro ##\n",
    "tabla_con_id_cliente = tabla_final\n",
    "\n",
    "df = tabla_final.drop('ID_CLIENTE', axis=1)\n",
    "#visualizamos los datos\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['ID_SEGMENTO_VALOR', 'EDAD', 'ID_GENERO', 'RENTA', 'DEBITO_DIR', 'ID_EMPLEADO', 'ANTIGUEDAD', 'EDAD_PUNTAJE']]\n",
    "y = df['ACEPTADO']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-19 18:49:37,053] A new study created in memory with name: rlog_artif\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:49:40,268] Trial 0 finished with value: 0.9211364843335104 and parameters: {'C': 13.152923535284875, 'l1_ratio': 0.5476981453244353}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:49:43,451] Trial 1 finished with value: 0.9211364843335104 and parameters: {'C': 7.288151816620559, 'l1_ratio': 0.9187239565690498}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:49:46,597] Trial 2 finished with value: 0.9211364843335104 and parameters: {'C': 49.121686391859, 'l1_ratio': 0.6233025496578846}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:49:49,776] Trial 3 finished with value: 0.9211364843335104 and parameters: {'C': 10.59807917756902, 'l1_ratio': 0.17419668086163714}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:49:53,778] Trial 4 finished with value: 0.9211364843335104 and parameters: {'C': 6.8083373853623055, 'l1_ratio': 0.3284336189344487}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:49:57,610] Trial 5 finished with value: 0.9211364843335104 and parameters: {'C': 1.1959064634193646, 'l1_ratio': 0.3529024500723742}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:00,613] Trial 6 finished with value: 0.9211364843335104 and parameters: {'C': 74.45133720658826, 'l1_ratio': 0.9610802282116269}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:05,151] Trial 7 finished with value: 0.9211364843335104 and parameters: {'C': 24.079124471921254, 'l1_ratio': 0.286709718963986}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:08,542] Trial 8 finished with value: 0.9211364843335104 and parameters: {'C': 69.3595102918162, 'l1_ratio': 0.7228869610858112}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:11,408] Trial 9 finished with value: 0.9211364843335104 and parameters: {'C': 75.958725417692, 'l1_ratio': 0.23755919280913276}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:14,436] Trial 10 finished with value: 0.9211364843335104 and parameters: {'C': 2.9956691952910184, 'l1_ratio': 0.5339389142526969}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:17,324] Trial 11 finished with value: 0.9211364843335104 and parameters: {'C': 12.80301285620074, 'l1_ratio': 0.9662208634377853}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:20,283] Trial 12 finished with value: 0.9211364843335104 and parameters: {'C': 5.386617239034985, 'l1_ratio': 0.7869536610313754}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:23,466] Trial 13 finished with value: 0.9211364843335104 and parameters: {'C': 21.36031101636121, 'l1_ratio': 0.4901451334737849}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:26,421] Trial 14 finished with value: 0.9211364843335104 and parameters: {'C': 3.8555045903991774, 'l1_ratio': 0.7696755779044189}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:29,543] Trial 15 finished with value: 0.9211364843335104 and parameters: {'C': 17.726997034139515, 'l1_ratio': 0.6223050078187037}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:32,576] Trial 16 finished with value: 0.9211364843335104 and parameters: {'C': 30.83220519612788, 'l1_ratio': 0.1092425884964619}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:35,751] Trial 17 finished with value: 0.9211364843335104 and parameters: {'C': 9.667741940571732, 'l1_ratio': 0.45227598638766875}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:38,732] Trial 18 finished with value: 0.9211364843335104 and parameters: {'C': 32.77219065393594, 'l1_ratio': 0.8503639383283299}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:41,814] Trial 19 finished with value: 0.9211364843335104 and parameters: {'C': 15.619487047825144, 'l1_ratio': 0.6564638537826658}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:44,724] Trial 20 finished with value: 0.9211364843335104 and parameters: {'C': 8.5049322217407, 'l1_ratio': 0.8568432433338556}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:47,925] Trial 21 finished with value: 0.9211364843335104 and parameters: {'C': 41.84573495718991, 'l1_ratio': 0.5895401788321836}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:50,897] Trial 22 finished with value: 0.9211364843335104 and parameters: {'C': 46.85392289041198, 'l1_ratio': 0.44042979252097336}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:54,681] Trial 23 finished with value: 0.9211364843335104 and parameters: {'C': 15.218702336628818, 'l1_ratio': 0.6672055400703689}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:50:58,502] Trial 24 finished with value: 0.9211364843335104 and parameters: {'C': 24.208817616949283, 'l1_ratio': 0.5659978669624629}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:01,615] Trial 25 finished with value: 0.9211364843335104 and parameters: {'C': 90.44881316479305, 'l1_ratio': 0.6883691059773613}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:04,586] Trial 26 finished with value: 0.9211364843335104 and parameters: {'C': 49.67059378141264, 'l1_ratio': 0.599381906602942}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:07,546] Trial 27 finished with value: 0.9211364843335104 and parameters: {'C': 14.882007945407798, 'l1_ratio': 0.5376793476873205}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:10,607] Trial 28 finished with value: 0.9211364843335104 and parameters: {'C': 11.230624838377084, 'l1_ratio': 0.4194591184893595}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:13,587] Trial 29 finished with value: 0.9211364843335104 and parameters: {'C': 8.107984757055132, 'l1_ratio': 0.7174020261023388}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:16,489] Trial 30 finished with value: 0.9211364843335104 and parameters: {'C': 11.307963466965003, 'l1_ratio': 0.6317035893093333}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:19,445] Trial 31 finished with value: 0.9211364843335104 and parameters: {'C': 5.899481205143489, 'l1_ratio': 0.34367861413856765}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:22,521] Trial 32 finished with value: 0.9211364843335104 and parameters: {'C': 6.650935507957527, 'l1_ratio': 0.4046905747931949}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:25,465] Trial 33 finished with value: 0.9211364843335104 and parameters: {'C': 19.608979366977877, 'l1_ratio': 0.4969621836489018}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:28,379] Trial 34 finished with value: 0.9211364843335104 and parameters: {'C': 11.677922666356096, 'l1_ratio': 0.8792830198413706}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:31,439] Trial 35 finished with value: 0.9211364843335104 and parameters: {'C': 8.149021698245258, 'l1_ratio': 0.9965240510236858}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:34,628] Trial 36 finished with value: 0.9211364843335104 and parameters: {'C': 27.364196318090258, 'l1_ratio': 0.2814699328572805}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:37,544] Trial 37 finished with value: 0.9211364843335104 and parameters: {'C': 4.822053549400794, 'l1_ratio': 0.915560185084048}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:40,976] Trial 38 finished with value: 0.9211364843335104 and parameters: {'C': 2.66556258254316, 'l1_ratio': 0.7833291993950742}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:43,791] Trial 39 finished with value: 0.9211364843335104 and parameters: {'C': 21.25522636184739, 'l1_ratio': 0.3858546424209256}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:47,104] Trial 40 finished with value: 0.9211364843335104 and parameters: {'C': 59.62091829072936, 'l1_ratio': 0.19036747629093043}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:50,649] Trial 41 finished with value: 0.9211364843335104 and parameters: {'C': 9.627884717660853, 'l1_ratio': 0.3542786355040523}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:54,944] Trial 42 finished with value: 0.9211364843335104 and parameters: {'C': 7.221750396474643, 'l1_ratio': 0.5275716926334535}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:51:58,528] Trial 43 finished with value: 0.9211364843335104 and parameters: {'C': 14.163811729080603, 'l1_ratio': 0.23594601316690117}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:52:01,607] Trial 44 finished with value: 0.9211364843335104 and parameters: {'C': 4.523802811971096, 'l1_ratio': 0.47546025573407497}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:52:05,203] Trial 45 finished with value: 0.9211364843335104 and parameters: {'C': 6.354563768922672, 'l1_ratio': 0.747087386233889}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:52:08,287] Trial 46 finished with value: 0.9211364843335104 and parameters: {'C': 12.549309023780557, 'l1_ratio': 0.8222029468592841}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:52:11,477] Trial 47 finished with value: 0.9211364843335104 and parameters: {'C': 16.62205971862366, 'l1_ratio': 0.7077204397665986}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:52:14,819] Trial 48 finished with value: 0.9211364843335104 and parameters: {'C': 9.970846838361522, 'l1_ratio': 0.9325493921513022}. Best is trial 0 with value: 0.9211364843335104.\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
      "/var/folders/cc/3mg7xtb906vcdzf2brdmqt500000gn/T/ipykernel_7013/1526194459.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "[I 2023-06-19 18:52:18,202] Trial 49 finished with value: 0.9211364843335104 and parameters: {'C': 34.68482939218313, 'l1_ratio': 0.7523190970987648}. Best is trial 0 with value: 0.9211364843335104.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space\n",
    "    \n",
    "    c_space=trial.suggest_loguniform('C',10e-1, 100)\n",
    "    l1_rat_space=trial.suggest_uniform('l1_ratio',0.1, 1)\n",
    "    \n",
    "\n",
    "    clf =LogisticRegression(max_iter = 4000,penalty='l2',\n",
    "                            random_state=2,C=c_space,l1_ratio=l1_rat_space)\n",
    "    \n",
    "    score = cross_val_score(clf, X_train, y_train, scoring='accuracy',\n",
    "                            cv=4).mean()\n",
    "    return score\n",
    "\n",
    "study_rl = optuna.create_study(study_name=\"rlog_artif\",\n",
    "                            direction=\"maximize\",\n",
    "                              pruner=optuna.pruners.HyperbandPruner(max_resource=\"auto\"),\n",
    "                            sampler=TPESampler())\n",
    "study_rl.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 13.152923535284875, 'l1_ratio': 0.5476981453244353}\n"
     ]
    }
   ],
   "source": [
    "print(study_rl.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=13.152923535284875, l1_ratio=0.5476981453244353,\n",
       "                   max_iter=4000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=13.152923535284875, l1_ratio=0.5476981453244353,\n",
       "                   max_iter=4000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=13.152923535284875, l1_ratio=0.5476981453244353,\n",
       "                   max_iter=4000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Inicializamos el modelo usando la libreria de python\n",
    "logit = LogisticRegression(max_iter = 4000, penalty='l2', l1_ratio=0.5476981453244353, C=13.152923535284875)\n",
    "# Ajustamos nuestro modelo con los datos que reservamos para \"entrenar\" al modelo con la historia disponible\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/scipy/optimize/_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/savkaaldunce/Library/Python/3.9/lib/python/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0, solver='newton-cg')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl_opt = LogisticRegression(random_state = 0, solver = \"newton-cg\") #Combinación Óptima\n",
    "rl_opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.014704402022798702,\n",
       " 0.02253277199302737,\n",
       " 0.015643811700076043,\n",
       " 0.015309402626095172,\n",
       " 0.015445477580106896,\n",
       " 0.01564054218604935,\n",
       " 0.015354555491814694,\n",
       " 0.022496882736127495,\n",
       " 0.015354726390637001,\n",
       " 0.014895354516352639,\n",
       " 0.021684254636488706,\n",
       " 0.015330920871668803,\n",
       " 0.015620367522463522,\n",
       " 0.020520645422725487,\n",
       " 0.23400256160410512,\n",
       " 0.02253059604553938,\n",
       " 0.015612936204644337,\n",
       " 0.021302939941498622,\n",
       " 0.015051939317902172,\n",
       " 0.015343233893669185,\n",
       " 0.021688761811032096,\n",
       " 0.020938117576520174,\n",
       " 0.022101715961867618,\n",
       " 0.01536358287142602,\n",
       " 0.015336734772157811,\n",
       " 0.022490971230746653,\n",
       " 0.02487014861117813,\n",
       " 0.2728125135869336,\n",
       " 0.02526307977446949,\n",
       " 0.028494345944437442,\n",
       " 0.28327051611855025,\n",
       " 0.02198665905945906,\n",
       " 0.025194583958174716,\n",
       " 0.2234744043029739,\n",
       " 0.022074978563759895,\n",
       " 0.013942635569586687,\n",
       " 0.015658147706576205,\n",
       " 0.025209462438782287,\n",
       " 0.1631630781802363,\n",
       " 0.015442288814041895,\n",
       " 0.02246930425872653,\n",
       " 0.017606790869750814,\n",
       " 0.02209181574384873,\n",
       " 0.17703674502597047,\n",
       " 0.022142534476301812,\n",
       " 0.03497138366844613,\n",
       " 0.018397953735861308,\n",
       " 0.03089526378543523,\n",
       " 0.18392385381594947,\n",
       " 0.16598563712505582,\n",
       " 0.027569063861858586,\n",
       " 0.028089364657848184,\n",
       " 0.02697960450612151,\n",
       " 0.014225249182885893,\n",
       " 0.015623687173953139,\n",
       " 0.020514508090565344,\n",
       " 0.01455558464109656,\n",
       " 0.015321853594096964,\n",
       " 0.015353928247601603,\n",
       " 0.014478491627085713,\n",
       " 0.022076348532414903,\n",
       " 0.014046808682165032,\n",
       " 0.015330250792189278,\n",
       " 0.020517546325194338,\n",
       " 0.022152454173875714,\n",
       " 0.015621012576314954,\n",
       " 0.021290120758615843,\n",
       " 0.015056308283541209,\n",
       " 0.02128203358220153,\n",
       " 0.01478952630139168,\n",
       " 0.015634457602093556,\n",
       " 0.02093369311559276,\n",
       " 0.015376944599681093,\n",
       " 0.02248784167119274,\n",
       " 0.021690808281921173,\n",
       " 0.026477006003411102,\n",
       " 0.015661201777104183,\n",
       " 0.020539566600543843,\n",
       " 0.015606636360214119,\n",
       " 0.015363065562850888,\n",
       " 0.021677535155426406,\n",
       " 0.021855292689495154,\n",
       " 0.015316417960316507,\n",
       " 0.015651404657717444,\n",
       " 0.014266668976792072,\n",
       " 0.01561334502647543,\n",
       " 0.015358011065659044,\n",
       " 0.1604407176628742,\n",
       " 0.022498410748220583,\n",
       " 0.018468654094035013,\n",
       " 0.02210739384496164,\n",
       " 0.015606579903302133,\n",
       " 0.01533029506922023,\n",
       " 0.021742590180144555,\n",
       " 0.022095658186181828,\n",
       " 0.015331620937281814,\n",
       " 0.014526707706236467,\n",
       " 0.01977556231597938,\n",
       " 0.022541437481938154,\n",
       " 0.01569174206586929,\n",
       " 0.02211660385631388,\n",
       " 0.022084142169091367,\n",
       " 0.015620358514279639,\n",
       " 0.015392334425672623,\n",
       " 0.22419139916276443,\n",
       " 0.17387525027259307,\n",
       " 0.2376149498147425,\n",
       " 0.022541235494430552,\n",
       " 0.014239183404164418,\n",
       " 0.019459042379305187,\n",
       " 0.020316181506902647,\n",
       " 0.022620925266043083,\n",
       " 0.014517942732711545,\n",
       " 0.01563493783494043,\n",
       " 0.014788352225836842,\n",
       " 0.015620012158036252,\n",
       " 0.022525973267609103,\n",
       " 0.023292818558153686,\n",
       " 0.014501047816761701,\n",
       " 0.0153323424461965,\n",
       " 0.02209737368786661,\n",
       " 0.02251658281518708,\n",
       " 0.015334454559841998,\n",
       " 0.23112592236398677,\n",
       " 0.013929816239184977,\n",
       " 0.021667192728841253,\n",
       " 0.02211898980692,\n",
       " 0.01943100329878271,\n",
       " 0.022495109162993566,\n",
       " 0.015368988714548218,\n",
       " 0.015323463097112489,\n",
       " 0.021712694901416182,\n",
       " 0.22340939333659673,\n",
       " 0.015628791531868365,\n",
       " 0.01446764789955254,\n",
       " 0.024392247577766316,\n",
       " 0.1941662441511087,\n",
       " 0.020886861707713034,\n",
       " 0.015323028116082387,\n",
       " 0.019416015107486084,\n",
       " 0.014451678415927694,\n",
       " 0.1741068205434497,\n",
       " 0.015317262038522664,\n",
       " 0.021332356301153432,\n",
       " 0.014248440692741808,\n",
       " 0.015060348970237128,\n",
       " 0.22404025299895136,\n",
       " 0.020433577973626747,\n",
       " 0.15834561228248484,\n",
       " 0.16852061671367013,\n",
       " 0.013522640187258387,\n",
       " 0.015322717475934543,\n",
       " 0.015373248711461741,\n",
       " 0.015619650174628599,\n",
       " 0.020902568478665198,\n",
       " 0.03487801471275743,\n",
       " 0.015643347874592105,\n",
       " 0.015589894744521665,\n",
       " 0.015328740580128716,\n",
       " 0.022527401375761015,\n",
       " 0.020202223934419575,\n",
       " 0.022520579243835194,\n",
       " 0.015331968487870976,\n",
       " 0.02255210741261596,\n",
       " 0.02180981682442554,\n",
       " 0.015320665888794244,\n",
       " 0.017466628469110554,\n",
       " 0.015049968578066023,\n",
       " 0.015453443672798836,\n",
       " 0.01533890401276836,\n",
       " 0.015654536979789396,\n",
       " 0.015311124713521473,\n",
       " 0.015630837060950774,\n",
       " 0.020883761016989643,\n",
       " 0.015323403273478775,\n",
       " 0.022161835991211357,\n",
       " 0.021676839190787237,\n",
       " 0.01534083025210798,\n",
       " 0.015340584256076937,\n",
       " 0.23738258686148972,\n",
       " 0.01427426335483533,\n",
       " 0.02212810237829163,\n",
       " 0.16620177982438133,\n",
       " 0.01563420410365597,\n",
       " 0.022473980828001817,\n",
       " 0.015069834009601667,\n",
       " 0.022104524270748604,\n",
       " 0.022101424396101254,\n",
       " 0.022086907756580416,\n",
       " 0.022067277821489276,\n",
       " 0.022477940743254942,\n",
       " 0.022106158147071866,\n",
       " 0.022508289563017005,\n",
       " 0.22413178433140118,\n",
       " 0.013966154483912068,\n",
       " 0.015353226955634491,\n",
       " 0.016606589035468734,\n",
       " 0.022648613593118275,\n",
       " 0.015604624415084178,\n",
       " 0.02094270135593828,\n",
       " 0.015320739375633836,\n",
       " 0.015332650895984347,\n",
       " 0.019764409318393523,\n",
       " 0.01374538996228092,\n",
       " 0.01452243983125631,\n",
       " 0.022112919214163192,\n",
       " 0.015326287584895418,\n",
       " 0.02087330024702209,\n",
       " 0.015326505238510028,\n",
       " 0.022524291900909446,\n",
       " 0.1558235333401945,\n",
       " 0.01396756831131979,\n",
       " 0.015056169234347596,\n",
       " 0.020899067686424595,\n",
       " 0.02091690679843839,\n",
       " 0.02208396297311924,\n",
       " 0.020940800502957286,\n",
       " 0.015629066657357176,\n",
       " 0.015393901212648511,\n",
       " 0.020437593598591566,\n",
       " 0.021694113429906292,\n",
       " 0.02169218258682852,\n",
       " 0.014241158945166242,\n",
       " 0.013481422431283219,\n",
       " 0.17705542022561305,\n",
       " 0.02185540761811651,\n",
       " 0.024364689955045885,\n",
       " 0.015358246553389564,\n",
       " 0.015330846934761503,\n",
       " 0.17664237936770238,\n",
       " 0.014512187112617831,\n",
       " 0.01771317939986103,\n",
       " 0.014765677193191306,\n",
       " 0.01562698338167483,\n",
       " 0.015348369785775444,\n",
       " 0.015116735373029324,\n",
       " 0.022091773683459118,\n",
       " 0.015630585410941752,\n",
       " 0.014234825800347314,\n",
       " 0.238126361828309,\n",
       " 0.015075404791022092,\n",
       " 0.015044927767132413,\n",
       " 0.01449733748771267,\n",
       " 0.02229049293039133,\n",
       " 0.020085537793946385,\n",
       " 0.02220591642126938,\n",
       " 0.02214768764369564,\n",
       " 0.16852349207963133,\n",
       " 0.015324548683018862,\n",
       " 0.022512614925253235,\n",
       " 0.021024420466828845,\n",
       " 0.02206391552846938,\n",
       " 0.022477380293143067,\n",
       " 0.2375516773578142,\n",
       " 0.022076463512893208,\n",
       " 0.015314718057607174,\n",
       " 0.014774057218527223,\n",
       " 0.015615841357099652,\n",
       " 0.2058482312675296,\n",
       " 0.02094469366188378,\n",
       " 0.022220590309086075,\n",
       " 0.019779668619189037,\n",
       " 0.02058349175148092,\n",
       " 0.022160828736893737,\n",
       " 0.022541276304674174,\n",
       " 0.015596375005793063,\n",
       " 0.015631650219874223,\n",
       " 0.017987613035664762,\n",
       " 0.014244954796924074,\n",
       " 0.014239376691868621,\n",
       " 0.015556807398266589,\n",
       " 0.015618124839645071,\n",
       " 0.2012628736811763,\n",
       " 0.020499935083325316,\n",
       " 0.17423949450161894,\n",
       " 0.022521847300819672,\n",
       " 0.02253922810200769,\n",
       " 0.35719479817987193,\n",
       " 0.040164245307832566,\n",
       " 0.015353131800405068,\n",
       " 0.015365664005791726,\n",
       " 0.014247132025867002,\n",
       " 0.01562909278633275,\n",
       " 0.014847430689102683,\n",
       " 0.2374078514778868,\n",
       " 0.021284841194768703,\n",
       " 0.020514270218463446,\n",
       " 0.01539514458922014,\n",
       " 0.013472260646631859,\n",
       " 0.015367507294315057,\n",
       " 0.013524446584168561,\n",
       " 0.019417999688531484,\n",
       " 0.015324630849890285,\n",
       " 0.022184034679376283,\n",
       " 0.015609929664208395,\n",
       " 0.01505242211034541,\n",
       " 0.1633810461595452,\n",
       " 0.0156343021268222,\n",
       " 0.015069254975509821,\n",
       " 0.015327579024006636,\n",
       " 0.020521870380929664,\n",
       " 0.014527735506959247,\n",
       " 0.015071069106673423,\n",
       " 0.013488264425554716,\n",
       " 0.02082000560400044,\n",
       " 0.0150819673621664,\n",
       " 0.015134562536141129,\n",
       " 0.013725895793425492,\n",
       " 0.01399439100796918,\n",
       " 0.014777228802860715,\n",
       " 0.014777119488117173,\n",
       " 0.015329650742151252,\n",
       " 0.01564391134686503,\n",
       " 0.022126485567814675,\n",
       " 0.015053157879793954,\n",
       " 0.022296502627526468,\n",
       " 0.17418843418086755,\n",
       " 0.021495075720708044,\n",
       " 0.01537498086960395,\n",
       " 0.015352660103243385,\n",
       " 0.01449045437013616,\n",
       " 0.015051335095794845,\n",
       " 0.015334948834416795,\n",
       " 0.01419172857576328,\n",
       " 0.015627422044730492,\n",
       " 0.015317173618201646,\n",
       " 0.015342614197066185,\n",
       " 0.021285018362219937,\n",
       " 0.020655071613875035,\n",
       " 0.015644454744963635,\n",
       " 0.021262168422044814,\n",
       " 0.01928742492591359,\n",
       " 0.015640065321696706,\n",
       " 0.018886958208480263,\n",
       " 0.015318424253129261,\n",
       " 0.015041556436292382,\n",
       " 0.015323096658642822,\n",
       " 0.015348984583585759,\n",
       " 0.015341240105137275,\n",
       " 0.015046795260282898,\n",
       " 0.013715804820846143,\n",
       " 0.014314665012059271,\n",
       " 0.015325962010655822,\n",
       " 0.022073447364113156,\n",
       " 0.014509060829584499,\n",
       " 0.015638571502542817,\n",
       " 0.18935903532078177,\n",
       " 0.015418766424348826,\n",
       " 0.02570545273516249,\n",
       " 0.1739685402940233,\n",
       " 0.016731247911333496,\n",
       " 0.015615031129935985,\n",
       " 0.16893200810026288,\n",
       " 0.019452564313301033,\n",
       " 0.022484370578049164,\n",
       " 0.015616903191331277,\n",
       " 0.014439603177774011,\n",
       " 0.022090922584640807,\n",
       " 0.015610546103833658,\n",
       " 0.23723012268843605,\n",
       " 0.015033045602508939,\n",
       " 0.0225832158173046,\n",
       " 0.015057653076035033,\n",
       " 0.014504082724153117,\n",
       " 0.015041662694655079,\n",
       " 0.02128333998298686,\n",
       " 0.18922161892755152,\n",
       " 0.015045261230267937,\n",
       " 0.02212908690046785,\n",
       " 0.01532395278154382,\n",
       " 0.015045825412798752,\n",
       " 0.022492612934430986,\n",
       " 0.022084325051409778,\n",
       " 0.020147160669622275,\n",
       " 0.015327220094937772,\n",
       " 0.021316184496206068,\n",
       " 0.015603252497658935,\n",
       " 0.015622932181370484,\n",
       " 0.021898994411982873,\n",
       " 0.020536896873887992,\n",
       " 0.15842062298223838,\n",
       " 0.015740363687737107,\n",
       " 0.014495175446655783,\n",
       " 0.02207845824054149,\n",
       " 0.022506916689078622,\n",
       " 0.015599046496884057,\n",
       " 0.022612998542527997,\n",
       " 0.021284385061480688,\n",
       " 0.0205434220852858,\n",
       " 0.015662460804665834,\n",
       " 0.022305607832863977,\n",
       " 0.015630205872057774,\n",
       " 0.02207654482999595,\n",
       " 0.014800240506402775,\n",
       " 0.015131099556770814,\n",
       " 0.015059482026230793,\n",
       " 0.015629601824377348,\n",
       " 0.020438339047950015,\n",
       " 0.02250280923178418,\n",
       " 0.014506697493086666,\n",
       " 0.020838720928789963,\n",
       " 0.02210770979498244,\n",
       " 0.015056694533060709,\n",
       " 0.015635359868349213,\n",
       " 0.022545293663657227,\n",
       " 0.0225310962341951,\n",
       " 0.01562930681187698,\n",
       " 0.015632784505197988,\n",
       " 0.01562635073779941,\n",
       " 0.01571220840019612,\n",
       " 0.01560424881441421,\n",
       " 0.015616552483285659,\n",
       " 0.015624744785163038,\n",
       " 0.015632263921934925,\n",
       " 0.015657960092088457,\n",
       " 0.02248637540839624,\n",
       " 0.015619307336791533,\n",
       " 0.022454256008008436,\n",
       " 0.027758029868112218,\n",
       " 0.014214183289758334,\n",
       " 0.01568136482759844,\n",
       " 0.0319337466183449,\n",
       " 0.022480611162817885,\n",
       " 0.2375420765964633,\n",
       " 0.019423976077465255,\n",
       " 0.022484849864071198,\n",
       " 0.015622912614988316,\n",
       " 0.02249289345174022,\n",
       " 0.2373608005273411,\n",
       " 0.022520975259894452,\n",
       " 0.015611718169039128,\n",
       " 0.024175737059752185,\n",
       " 0.022485762897961097,\n",
       " 0.01563301624695704,\n",
       " 0.022471461098942123,\n",
       " 0.022504762490623074,\n",
       " 0.01561721500065716,\n",
       " 0.015915878520688525,\n",
       " 0.022607175369378348,\n",
       " 0.01563016168340128,\n",
       " 0.015627015909657545,\n",
       " 0.015600071720314782,\n",
       " 0.02251560231024729,\n",
       " 0.022528532675673247,\n",
       " 0.015626095988180454,\n",
       " 0.2522849988736645,\n",
       " 0.022534576329660088,\n",
       " 0.022477464396629523,\n",
       " 0.02255969519481317,\n",
       " 0.022538099167181143,\n",
       " 0.015617731466810135,\n",
       " 0.015625340092200433,\n",
       " 0.022491861478883463,\n",
       " 0.02259401858561672,\n",
       " 0.015649975044243182,\n",
       " 0.015613978531643863,\n",
       " 0.015634660725549858,\n",
       " 0.022469005723903982,\n",
       " 0.02248400484465683,\n",
       " 0.02246710668171819,\n",
       " 0.015621551703358662,\n",
       " 0.020157286158127004,\n",
       " 0.01562912251150881,\n",
       " 0.015659437870710974,\n",
       " 0.015643515633877766,\n",
       " 0.015041468238905856,\n",
       " 0.02250233072153731,\n",
       " 0.022488511344676363,\n",
       " 0.015593741981108397,\n",
       " 0.015598697228467727,\n",
       " 0.031343588121746174,\n",
       " 0.01563495755275711,\n",
       " 0.015594620995288657,\n",
       " 0.015624907721376488,\n",
       " 0.015690195500110988,\n",
       " 0.01485381583507581,\n",
       " 0.021346483480210923,\n",
       " 0.022500075064796517,\n",
       " 0.015425784637015348,\n",
       " 0.022489866643210104,\n",
       " 0.022482677635896262,\n",
       " 0.015617475308899557,\n",
       " 0.02263231756628444,\n",
       " 0.02249195051426433,\n",
       " 0.022520056443579742,\n",
       " 0.015105832012453047,\n",
       " 0.022132372365532896,\n",
       " 0.02045084193282347,\n",
       " 0.015612960488093956,\n",
       " 0.024359010942159077,\n",
       " 0.2309762898891652,\n",
       " 0.02013242384872925,\n",
       " 0.01532533063274838,\n",
       " 0.04026563260369585,\n",
       " 0.01780761483119934,\n",
       " 0.019405974973649997,\n",
       " 0.026749225207126803,\n",
       " 0.01694060227841402,\n",
       " 0.022507752003980894,\n",
       " 0.02578113977969722,\n",
       " 0.22623975108536912,\n",
       " 0.04019391633017635,\n",
       " 0.02483637401983088,\n",
       " 0.2842586987269761,\n",
       " 0.22402150151369596,\n",
       " 0.2067884221333886,\n",
       " 0.026698427447600606,\n",
       " 0.04090348246353573,\n",
       " 0.024320358515218025,\n",
       " 0.01690070062422848,\n",
       " 0.2734829597326655,\n",
       " 0.016323854228926227,\n",
       " 0.01841856428856613,\n",
       " 0.03749559599688052,\n",
       " 0.35298366730145536,\n",
       " 0.022463024601204716,\n",
       " 0.015595590877430081,\n",
       " 0.022560939347853946,\n",
       " 0.015617920532620018,\n",
       " 0.015669945547100467,\n",
       " 0.02253228575714961,\n",
       " 0.022644297456405536,\n",
       " 0.020139644322564605,\n",
       " 0.022483624962374327,\n",
       " 0.017792864954139925,\n",
       " 0.01449957830307366,\n",
       " 0.022501294681232076,\n",
       " 0.01564145527582107,\n",
       " 0.015706048047482823,\n",
       " 0.022476464146324662,\n",
       " 0.176935482937028,\n",
       " 0.022537854905433644,\n",
       " 0.0225205485007678,\n",
       " 0.017339978805728212,\n",
       " 0.1656089932226769,\n",
       " 0.01564915442950343,\n",
       " 0.022706527585178424,\n",
       " 0.022596498458808466,\n",
       " 0.016387279364838768,\n",
       " 0.015646194327002354,\n",
       " 0.015637335269740725,\n",
       " 0.29660017234941677,\n",
       " 0.16292994593503093,\n",
       " 0.022502124260354726,\n",
       " 0.01564907586772361,\n",
       " 0.01570668653483504,\n",
       " 0.015690297067478032,\n",
       " 0.013976373127902968,\n",
       " 0.022469208075543635,\n",
       " 0.022476664656641495,\n",
       " 0.02249565697712667,\n",
       " 0.2272918197460407,\n",
       " 0.022511248087273093,\n",
       " 0.022093541054332512,\n",
       " 0.0156079965234297,\n",
       " 0.015345894533078872,\n",
       " 0.022461442156348974,\n",
       " 0.022508624087174186,\n",
       " 0.015597242081765373,\n",
       " 0.020873255962019582,\n",
       " 0.022461313371340857,\n",
       " 0.023087182926151063,\n",
       " 0.015609643322102094,\n",
       " 0.022570952014945772,\n",
       " 0.02249423380611421,\n",
       " 0.022623155139227722,\n",
       " 0.022468640884562446,\n",
       " 0.02249234861895294,\n",
       " 0.0394419379552726,\n",
       " 0.01576276446171424,\n",
       " 0.01561883978330786,\n",
       " 0.015622640675108485,\n",
       " 0.015639021098716142,\n",
       " 0.022791111634946334,\n",
       " 0.03499238193141865,\n",
       " 0.25899483715812394,\n",
       " 0.013549340029890375,\n",
       " 0.2699609566366524,\n",
       " 0.021857651438298535,\n",
       " 0.01954814858499472,\n",
       " 0.030825593825455428,\n",
       " 0.1949780627523661,\n",
       " 0.018789924004649326,\n",
       " 0.025241963965174908,\n",
       " 0.019757014145971665,\n",
       " 0.015620340300778688,\n",
       " 0.02396024145448185,\n",
       " 0.015690045846313783,\n",
       " 0.01561811701545942,\n",
       " 0.015636931750361314,\n",
       " 0.015610759182245108,\n",
       " 0.02251055463991013,\n",
       " 0.015641902387170496,\n",
       " 0.022485869144178515,\n",
       " 0.022558113969248745,\n",
       " 0.022466723872626226,\n",
       " 0.022525182091203785,\n",
       " 0.013731190574586726,\n",
       " 0.01988046958777247,\n",
       " 0.23742580027238036,\n",
       " 0.03139259844322016,\n",
       " 0.02564105395937676,\n",
       " 0.021537806695768883,\n",
       " 0.2689079721021458,\n",
       " 0.018628668439938198,\n",
       " 0.20414073960554263,\n",
       " 0.03747390173730913,\n",
       " 0.024339664981608142,\n",
       " 0.2727203856051052,\n",
       " 0.1713366106547578,\n",
       " 0.021183178450584223,\n",
       " 0.2494423388055364,\n",
       " 0.026530016609007178,\n",
       " 0.020431423718666342,\n",
       " 0.2748463025354227,\n",
       " 0.19701466312581595,\n",
       " 0.01346683729360575,\n",
       " 0.25997189138296806,\n",
       " 0.03492388723777902,\n",
       " 0.025252722204565797,\n",
       " 0.018969599781746452,\n",
       " 0.2411422152509574,\n",
       " 0.021500092161146653,\n",
       " 0.2212135297958133,\n",
       " 0.015079684076634098,\n",
       " 0.01841921941616412,\n",
       " 0.27289234670920426,\n",
       " 0.02442420606734572,\n",
       " 0.16085659053175647,\n",
       " 0.01560708979560119,\n",
       " 0.021731199176052485,\n",
       " 0.02254932356947242,\n",
       " 0.2176543094059879,\n",
       " 0.015616654157649046,\n",
       " 0.015616692911126941,\n",
       " 0.01562746665058282,\n",
       " 0.01563776588389028,\n",
       " 0.176712538991915,\n",
       " 0.01563413886652316,\n",
       " 0.015654324498760898,\n",
       " 0.022497276002641446,\n",
       " 0.015622579535158915,\n",
       " 0.015611335882963134,\n",
       " 0.022550686448465352,\n",
       " 0.01575274204331473,\n",
       " 0.2387661401349887,\n",
       " 0.022485622573928995,\n",
       " 0.23782202748368764,\n",
       " 0.023557802573557718,\n",
       " 0.022504255583309832,\n",
       " 0.02256577784076796,\n",
       " 0.022486599158486505,\n",
       " 0.030430594328904503,\n",
       " 0.015612588009530269,\n",
       " 0.013711187673094422,\n",
       " 0.021258796500205707,\n",
       " 0.022618154099146238,\n",
       " 0.03952663436399877,\n",
       " 0.23227406247126883,\n",
       " 0.25952919910913586,\n",
       " 0.3291934974813993,\n",
       " 0.014527908237383346,\n",
       " 0.2624724388305104,\n",
       " 0.01755006130296272,\n",
       " 0.015089870478694357,\n",
       " 0.025651930511543946,\n",
       " 0.25880086902318106,\n",
       " 0.26239761749985885,\n",
       " 0.027714407578770184,\n",
       " 0.028410552125078755,\n",
       " 0.018473233767262936,\n",
       " 0.015608763110891015,\n",
       " 0.02256291376226685,\n",
       " 0.01562042631842904,\n",
       " 0.015627986317995397,\n",
       " 0.01564025210261913,\n",
       " 0.022502396454549788,\n",
       " 0.022494609157491095,\n",
       " 0.01563486155955213,\n",
       " 0.022563773033359835,\n",
       " 0.015611324091080138,\n",
       " 0.022618154099146238,\n",
       " 0.022520782874269448,\n",
       " 0.022491956412382576,\n",
       " 0.01563032476625455,\n",
       " 0.015648072602138793,\n",
       " 0.02210407580475233,\n",
       " 0.23722275703483103,\n",
       " 0.020137500101740473,\n",
       " 0.022508019859706952,\n",
       " 0.022507707650983946,\n",
       " 0.015693395228697594,\n",
       " 0.015612401599214535,\n",
       " 0.015635978829469,\n",
       " 0.015687839967598444,\n",
       " 0.022580359459134402,\n",
       " 0.022545589689404105,\n",
       " 0.02254251294578734,\n",
       " 0.014790441446172874,\n",
       " 0.015669433786078688,\n",
       " 0.013735320276792298,\n",
       " 0.022061035873572835,\n",
       " 0.015333061367772353,\n",
       " 0.015058820513423034,\n",
       " 0.02210647740591213,\n",
       " 0.022093393214122087,\n",
       " 0.020097822273437316,\n",
       " 0.015329022251562175,\n",
       " 0.015351774283881976,\n",
       " 0.015636653771245314,\n",
       " 0.015618550672218503,\n",
       " 0.015790120316308696,\n",
       " 0.02207888200737172,\n",
       " 0.015349354448779143,\n",
       " 0.022125805945199823,\n",
       " 0.015633067910850194,\n",
       " 0.015645946474146785,\n",
       " 0.17655958934638388,\n",
       " 0.015616889318119245,\n",
       " 0.013968550806823112,\n",
       " 0.02255924466639478,\n",
       " 0.022502689955824003,\n",
       " 0.015631159266191953,\n",
       " 0.021678210935952857,\n",
       " 0.015617429139051823,\n",
       " 0.015335699375445792,\n",
       " 0.022508112754987333,\n",
       " 0.015683584229072522,\n",
       " 0.02257048135813594,\n",
       " 0.015630296434908257,\n",
       " 0.01568877137076831,\n",
       " 0.015626702921617806,\n",
       " 0.01561677041836665,\n",
       " 0.019752299718216074,\n",
       " 0.030460855914429284,\n",
       " 0.025878759863715992,\n",
       " 0.02261420632825979,\n",
       " 0.015656831958795248,\n",
       " 0.17672027442551513,\n",
       " 0.015623201805539026,\n",
       " 0.02257943740534755,\n",
       " 0.015612392095348355,\n",
       " 0.015615481742908428,\n",
       " 0.015621256612902774,\n",
       " 0.022570945879004083,\n",
       " 0.022506319644961612,\n",
       " 0.01573198581629152,\n",
       " 0.1767866872084025,\n",
       " 0.022486169437098684,\n",
       " 0.015605796754842768,\n",
       " 0.01568857766854311,\n",
       " 0.023002066228700165,\n",
       " 0.1769572013056519,\n",
       " 0.022566889420846243,\n",
       " 0.02250238897008841,\n",
       " 0.01568274560467578,\n",
       " 0.02251023130738101,\n",
       " 0.02254705105158273,\n",
       " 0.015622406339442963,\n",
       " 0.02249200522370593,\n",
       " 0.02249497332443946,\n",
       " 0.022483341176518165,\n",
       " 0.015688114166552494,\n",
       " 0.015625276727035925,\n",
       " 0.022528383577203274,\n",
       " 0.02255762661199025,\n",
       " 0.019775830183409122,\n",
       " 0.01563215671434615,\n",
       " 0.01566462571527126,\n",
       " 0.26355678006856736,\n",
       " 0.01576525286572612,\n",
       " 0.015661137113301183,\n",
       " 0.021724769320405204,\n",
       " 0.015644010158944885,\n",
       " 0.01563085826085925,\n",
       " 0.015736112504012734,\n",
       " 0.015617003291085119,\n",
       " 0.23722268136601488,\n",
       " 0.02251278239175763,\n",
       " 0.01560532806913416,\n",
       " 0.015619043101341238,\n",
       " 0.022491451131276766,\n",
       " 0.01561075906099617,\n",
       " 0.022531741881969276,\n",
       " 0.01561368570422343,\n",
       " 0.015620066691317115,\n",
       " 0.015642453081997455,\n",
       " 0.015628949563050925,\n",
       " 0.02250107582102258,\n",
       " 0.015614497681846015,\n",
       " 0.019816806336612234,\n",
       " 0.34107815432542965,\n",
       " 0.024835552485345122,\n",
       " 0.2239075284284302,\n",
       " 0.27975660745990083,\n",
       " 0.024916890308615994,\n",
       " 0.22097873887256508,\n",
       " 0.26071284107551357,\n",
       " 0.018490787456292318,\n",
       " 0.02391437591985767,\n",
       " 0.020121141471914197,\n",
       " 0.2119002224292216,\n",
       " 0.01941472970428084,\n",
       " 0.04849855112872426,\n",
       " 0.02391134711867449,\n",
       " 0.014219764580641432,\n",
       " 0.017257185832961788,\n",
       " 0.039469657167561935,\n",
       " 0.032688106929325375,\n",
       " 0.015497760291516406,\n",
       " 0.025259434602342302,\n",
       " 0.028420365089565604,\n",
       " 0.02654342994690925,\n",
       " 0.01511038806594461,\n",
       " 0.27268478477698505,\n",
       " 0.023592952995620024,\n",
       " 0.02703694861265562,\n",
       " 0.027766351651988735,\n",
       " 0.015619155072945576,\n",
       " 0.015625545435299478,\n",
       " 0.015689764013566556,\n",
       " 0.022490073753401413,\n",
       " 0.022514226048635136,\n",
       " 0.015608686930863602,\n",
       " 0.02248189358062449,\n",
       " 0.022492742783855175,\n",
       " 0.015619186204952644,\n",
       " 0.01561593477928687,\n",
       " 0.02255719473824532,\n",
       " 0.02219957673881389,\n",
       " 0.014768355707528425,\n",
       " 0.1676193336403824,\n",
       " 0.02254678122056863,\n",
       " 0.25262767933534125,\n",
       " 0.1656815118949024,\n",
       " 0.020569874878942775,\n",
       " 0.01560691814775823,\n",
       " 0.02496544929733442,\n",
       " 0.014515149941320178,\n",
       " 0.015666437269485245,\n",
       " 0.01476313835133935,\n",
       " 0.01563044959473789,\n",
       " 0.022056714048449687,\n",
       " 0.015624783861789851,\n",
       " 0.02211629213343621,\n",
       " 0.014245930483801187,\n",
       " 0.16286886966814998,\n",
       " 0.022071705769080727,\n",
       " 0.01559467082339946,\n",
       " 0.022108822734125413,\n",
       " 0.02211015283166087,\n",
       " 0.017532855924162084,\n",
       " 0.015351118617633564,\n",
       " 0.015333058940587493,\n",
       " 0.021902178024653586,\n",
       " 0.015369966664438376,\n",
       " 0.01534345021962679,\n",
       " 0.01535784573866169,\n",
       " 0.1691390203756631,\n",
       " 0.027528089623483708,\n",
       " 0.015180426276895432,\n",
       " 0.015042137534786355,\n",
       " 0.020157247977667467,\n",
       " 0.01980941832754858,\n",
       " 0.0220763370769845,\n",
       " 0.022235331181704298,\n",
       " 0.01533890900302682,\n",
       " 0.01505185190862859,\n",
       " 0.022591461535678772,\n",
       " 0.014505097877949468,\n",
       " 0.17704673117028438,\n",
       " 0.021718822980842063,\n",
       " 0.023961300320733337,\n",
       " 0.021772995784104486,\n",
       " 0.015395444430403447,\n",
       " 0.021802248041599546,\n",
       " 0.013989029396498365,\n",
       " 0.015053519745653643,\n",
       " 0.022541069733437606,\n",
       " 0.02278854796112313,\n",
       " 0.01565310498762818,\n",
       " 0.01565038088527063,\n",
       " 0.022079209271538055,\n",
       " 0.015067865558718004,\n",
       " 0.021705789099481374,\n",
       " 0.015383074179547483,\n",
       " 0.015613966055633286,\n",
       " 0.022116005413611833,\n",
       " 0.015341625802921666,\n",
       " 0.015660339792041282,\n",
       " 0.02214505593950018,\n",
       " 0.028392870843027163,\n",
       " 0.014252234452864105,\n",
       " 0.015356813502460818,\n",
       " 0.021718718518158497,\n",
       " 0.015362958024259877,\n",
       " 0.015634993891892122,\n",
       " 0.022246384762049116,\n",
       " 0.022509426609077603,\n",
       " 0.1713240805899882,\n",
       " 0.015635124297550908,\n",
       " 0.014763565911414842,\n",
       " 0.013732043869499068,\n",
       " 0.02211295487310549,\n",
       " 0.015327814632921754,\n",
       " 0.02208068436160022,\n",
       " 0.014808971783562833,\n",
       " 0.021690015358256442,\n",
       " 0.015351637513026203,\n",
       " 0.015351051815168755,\n",
       " 0.015367252132073536,\n",
       " 0.014811077890351932,\n",
       " 0.01942736257311544,\n",
       " 0.015343669409549288,\n",
       " 0.022518507413485475,\n",
       " 0.02167661721207138,\n",
       " 0.02081490191372732,\n",
       " 0.23452364060636516,\n",
       " 0.013473097153078902,\n",
       " 0.015658336995449246,\n",
       " 0.01535723704913865,\n",
       " 0.019886887604307374,\n",
       " 0.01565448120343467,\n",
       " 0.01533909501418891,\n",
       " 0.02214519666381011,\n",
       " 0.02206832972629867,\n",
       " 0.02213133143643394,\n",
       " 0.022065360718487387,\n",
       " 0.022502668348240704,\n",
       " 0.020505327786678806,\n",
       " 0.01925811614865252,\n",
       " 0.02020249994362507,\n",
       " 0.0209363967036998,\n",
       " 0.015392387817765998,\n",
       " 0.02208548847406782,\n",
       " 0.23742972042900032,\n",
       " 0.015614327909401697,\n",
       " 0.020147942980089383,\n",
       " 0.02167260733696137,\n",
       " 0.2377813404491382,\n",
       " 0.021731652783531615,\n",
       " 0.015343986368694832,\n",
       " 0.022074281517485063,\n",
       " 0.015606194044024186,\n",
       " 0.02053085857049851,\n",
       " 0.022120409337562163,\n",
       " 0.015377577264393243,\n",
       " 0.015062328818048889,\n",
       " 0.022076870229093278,\n",
       " 0.02054771473894184,\n",
       " 0.01479483556163609,\n",
       " 0.015114275086208426,\n",
       " 0.02387234616757484,\n",
       " 0.022588060741054797,\n",
       " 0.015335238690041294,\n",
       " 0.020824260945470317,\n",
       " 0.01535829114865427,\n",
       " 0.23720502903524143,\n",
       " 0.2274273069699571,\n",
       " 0.015325133325892176,\n",
       " 0.17696181907899827,\n",
       " 0.022114984710287368,\n",
       " 0.015665710387394113,\n",
       " 0.015352137610587695,\n",
       " 0.02210755034819951,\n",
       " 0.015624435330800712,\n",
       " 0.022535651017473523,\n",
       " 0.23724047042009816,\n",
       " 0.015344646593042898,\n",
       " 0.022090376849968254,\n",
       " 0.015361780742973572,\n",
       " 0.022230304269113585,\n",
       " 0.02208913654254376,\n",
       " 0.16165660976523438,\n",
       " 0.01567653708289649,\n",
       " 0.013751698871148795,\n",
       " 0.022482051828757108,\n",
       " 0.022559114876868975,\n",
       " 0.020930085683093624,\n",
       " 0.015099488083962886,\n",
       " 0.020930487779129467,\n",
       " 0.174378888207711,\n",
       " 0.015594378761135588,\n",
       " 0.014512460940629315,\n",
       " 0.01503820660837239,\n",
       " 0.22757057069055067,\n",
       " 0.014493421051674445,\n",
       " 0.022086902878289814,\n",
       " 0.015339503391481896,\n",
       " 0.014462079979937993,\n",
       " 0.014281972600076633,\n",
       " 0.015066923075475906,\n",
       " 0.022506388861014616,\n",
       " 0.015649282186280096,\n",
       " 0.014502032540403097,\n",
       " 0.02252238019476986,\n",
       " 0.015609318188983907,\n",
       " 0.015632640945082443,\n",
       " 0.014308381872732208,\n",
       " 0.01424373800901792,\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecir sobre los datos que dejamos para probar nuestro modelo usando la probabilidad\n",
    "proba_logit = rl_opt.predict_proba(X)\n",
    "len(proba_logit)\n",
    "\n",
    "proba_logit_aceptar = []\n",
    "\n",
    "for i in range (len(proba_logit)):\n",
    "    proba_logit_aceptar.append(proba_logit[i][1])\n",
    "\n",
    "proba_logit_aceptar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probabilidad_de_aceptar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602555</th>\n",
       "      <td>0.025353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602556</th>\n",
       "      <td>0.020302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602557</th>\n",
       "      <td>0.012638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602558</th>\n",
       "      <td>0.080413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602559</th>\n",
       "      <td>0.029372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602560 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        probabilidad_de_aceptar\n",
       "0                      0.014704\n",
       "1                      0.022533\n",
       "2                      0.015644\n",
       "3                      0.015309\n",
       "4                      0.015445\n",
       "...                         ...\n",
       "602555                 0.025353\n",
       "602556                 0.020302\n",
       "602557                 0.012638\n",
       "602558                 0.080413\n",
       "602559                 0.029372\n",
       "\n",
       "[602560 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proba = pd.DataFrame({'probabilidad_de_aceptar':proba_logit_aceptar})\n",
    "df_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CTE</th>\n",
       "      <th>DEBITO_DIR</th>\n",
       "      <th>ID_EMPLEADO</th>\n",
       "      <th>ID_SEGMENTO_VALOR</th>\n",
       "      <th>ANTIGUEDAD</th>\n",
       "      <th>ID_CLIENTE</th>\n",
       "      <th>RENTA</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>EDAD_PUNTAJE</th>\n",
       "      <th>ID_GENERO</th>\n",
       "      <th>ACEPTADO</th>\n",
       "      <th>probabilidad_de_aceptar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1375586.0</td>\n",
       "      <td>87218.10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1050612.0</td>\n",
       "      <td>122179.11</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1050613.0</td>\n",
       "      <td>119775.54</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1050615.0</td>\n",
       "      <td>22220.04</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1050616.0</td>\n",
       "      <td>295590.36</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>899549.0</td>\n",
       "      <td>97397.16</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1441442.0</td>\n",
       "      <td>168445.62</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1454431.0</td>\n",
       "      <td>53689.02</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>56812.0</td>\n",
       "      <td>64404.21</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>981034.0</td>\n",
       "      <td>97879.50</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602560 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CT_CTE  DEBITO_DIR  ID_EMPLEADO  ID_SEGMENTO_VALOR  ANTIGUEDAD  \\\n",
       "0          1.0         0.0          0.0                2.0         6.0   \n",
       "1          1.0         0.0          0.0                1.0        35.0   \n",
       "2          0.0         0.0          0.0                1.0        35.0   \n",
       "3          1.0         0.0          0.0                1.0        35.0   \n",
       "4          1.0         0.0          0.0                1.0        35.0   \n",
       "...        ...         ...          ...                ...         ...   \n",
       "602555     0.0         0.0          0.0                2.0        62.0   \n",
       "602556     0.0         0.0          0.0                2.0         7.0   \n",
       "602557     0.0         0.0          0.0                1.0         6.0   \n",
       "602558     0.0         0.0          0.0                2.0       229.0   \n",
       "602559     0.0         0.0          0.0                2.0        52.0   \n",
       "\n",
       "        ID_CLIENTE      RENTA  EDAD  EDAD_PUNTAJE  ID_GENERO  ACEPTADO  \\\n",
       "0        1375586.0   87218.10  36.0           3.0        1.0       0.0   \n",
       "1        1050612.0  122179.11  23.0           1.0        0.0       0.0   \n",
       "2        1050613.0  119775.54  23.0           1.0        1.0       0.0   \n",
       "3        1050615.0   22220.04  24.0           1.0        1.0       0.0   \n",
       "4        1050616.0  295590.36  24.0           1.0        1.0       0.0   \n",
       "...            ...        ...   ...           ...        ...       ...   \n",
       "602555    899549.0   97397.16  41.0           6.0        1.0       0.0   \n",
       "602556   1441442.0  168445.62  34.0           2.0        0.0       0.0   \n",
       "602557   1454431.0   53689.02  24.0           1.0        1.0       0.0   \n",
       "602558     56812.0   64404.21  61.0           7.0        0.0       0.0   \n",
       "602559    981034.0   97879.50  54.0           7.0        0.0       0.0   \n",
       "\n",
       "        probabilidad_de_aceptar  \n",
       "0                      0.014704  \n",
       "1                      0.022533  \n",
       "2                      0.015644  \n",
       "3                      0.015309  \n",
       "4                      0.015445  \n",
       "...                         ...  \n",
       "602555                 0.025353  \n",
       "602556                 0.020302  \n",
       "602557                 0.012638  \n",
       "602558                 0.080413  \n",
       "602559                 0.029372  \n",
       "\n",
       "[602560 rows x 12 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_con_id_cliente_mas_probabilidad = pd.merge(tabla_con_id_cliente, df_proba, left_index=True, right_index=True)\n",
    "\n",
    "tabla_con_id_cliente_mas_probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CT_CTE</th>\n",
       "      <th>DEBITO_DIR</th>\n",
       "      <th>ID_EMPLEADO</th>\n",
       "      <th>ID_SEGMENTO_VALOR</th>\n",
       "      <th>ANTIGUEDAD</th>\n",
       "      <th>ID_CLIENTE</th>\n",
       "      <th>RENTA</th>\n",
       "      <th>EDAD</th>\n",
       "      <th>EDAD_PUNTAJE</th>\n",
       "      <th>ID_GENERO</th>\n",
       "      <th>ACEPTADO</th>\n",
       "      <th>probabilidad_de_aceptar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>98717.0</td>\n",
       "      <td>21674246.67</td>\n",
       "      <td>47.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>19398.0</td>\n",
       "      <td>644710.38</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281523</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>48404.0</td>\n",
       "      <td>22034738.76</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.732796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>16233.0</td>\n",
       "      <td>207387.69</td>\n",
       "      <td>47.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>19929.0</td>\n",
       "      <td>36034.77</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.729130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597797</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1436134.0</td>\n",
       "      <td>67531.65</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470693</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1402635.0</td>\n",
       "      <td>63119.28</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597871</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1440072.0</td>\n",
       "      <td>55267.65</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566252</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1400657.0</td>\n",
       "      <td>53738.85</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470034</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1401811.0</td>\n",
       "      <td>50074.32</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602560 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CT_CTE  DEBITO_DIR  ID_EMPLEADO  ID_SEGMENTO_VALOR  ANTIGUEDAD  \\\n",
       "269471     0.0         1.0          0.0                2.0       205.0   \n",
       "275354     0.0         1.0          0.0                3.0       241.0   \n",
       "281523     1.0         1.0          0.0                2.0       217.0   \n",
       "276236     0.0         1.0          0.0                3.0       244.0   \n",
       "275184     0.0         1.0          0.0                3.0       240.0   \n",
       "...        ...         ...          ...                ...         ...   \n",
       "597797     1.0         0.0          0.0                1.0         1.0   \n",
       "470693     1.0         0.0          0.0                1.0         1.0   \n",
       "597871     1.0         0.0          0.0                1.0         1.0   \n",
       "566252     0.0         0.0          0.0                1.0         1.0   \n",
       "470034     1.0         0.0          0.0                1.0         1.0   \n",
       "\n",
       "        ID_CLIENTE        RENTA  EDAD  EDAD_PUNTAJE  ID_GENERO  ACEPTADO  \\\n",
       "269471     98717.0  21674246.67  47.0          10.0        0.0       0.0   \n",
       "275354     19398.0    644710.38  46.0          10.0        0.0       1.0   \n",
       "281523     48404.0  22034738.76  45.0          10.0        1.0       1.0   \n",
       "276236     16233.0    207387.69  47.0          10.0        0.0       1.0   \n",
       "275184     19929.0     36034.77  46.0          10.0        0.0       1.0   \n",
       "...            ...          ...   ...           ...        ...       ...   \n",
       "597797   1436134.0     67531.65  31.0           1.0        1.0       0.0   \n",
       "470693   1402635.0     63119.28  31.0           1.0        1.0       0.0   \n",
       "597871   1440072.0     55267.65  31.0           1.0        1.0       0.0   \n",
       "566252   1400657.0     53738.85  31.0           1.0        1.0       0.0   \n",
       "470034   1401811.0     50074.32  31.0           1.0        1.0       0.0   \n",
       "\n",
       "        probabilidad_de_aceptar  \n",
       "269471                 0.777377  \n",
       "275354                 0.734382  \n",
       "281523                 0.732796  \n",
       "276236                 0.731860  \n",
       "275184                 0.729130  \n",
       "...                         ...  \n",
       "597797                 0.010742  \n",
       "470693                 0.010740  \n",
       "597871                 0.010738  \n",
       "566252                 0.010737  \n",
       "470034                 0.010736  \n",
       "\n",
       "[602560 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_con_id_cliente_mas_probabilidad = tabla_con_id_cliente_mas_probabilidad.sort_values(by='probabilidad_de_aceptar', ascending = False)\n",
    "tabla_con_id_cliente_mas_probabilidad.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_con_id_cliente_mas_probabilidad.to_csv(r'resultados_modelos\\Resultados_Regresion_Logistica.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
